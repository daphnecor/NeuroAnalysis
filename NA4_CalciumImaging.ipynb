{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NA4_CalciumImaging.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daphnecor/NeuroAnalysis/blob/main/NA4_CalciumImaging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7UTyxuj_jad"
      },
      "source": [
        "## Neuro Analysis 4: Calcium imaging\n",
        "\n",
        "```\n",
        "Student: Daphne Cornelisse 1066862\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU1PO4D6_jbA"
      },
      "source": [
        "##import python standard libraries\n",
        "import numpy as np\n",
        "import pylab as pl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import pickle\n",
        "import psutil\n",
        "import logging\n",
        "import os\n",
        "\n",
        "##import caiman and caiman funcions that will be used\n",
        "import caiman as cm\n",
        "from caiman.motion_correction import MotionCorrect, high_pass_filter_space\n",
        "from caiman.source_extraction.cnmf import params as params\n",
        "from caiman.source_extraction import cnmf\n",
        "from caiman.source_extraction.cnmf.cnmf import load_CNMF\n",
        "from caiman.base.movies import load_movie_chain\n",
        "\n",
        "##import auxiliary functions for plotting file\n",
        "import auxiliary_functions\n",
        "from ipywidgets import interact\n",
        "import ipywidgets as widgets\n",
        "\n",
        "from tqdm import tqdm as tqdm\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLx7yZ0W_jbI"
      },
      "source": [
        "data_dir = '/Users/Daphne/Desktop/data/'           # define your data directory\n",
        "figures_dir = '/Users/Daphne/Desktop/figures/'     # define your results directory"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8GVLBKo_jbK"
      },
      "source": [
        "input_tif_file_path_FOV = data_dir + 'raw/' + 'calcium_video.tif'   # define the path of the raw FOV movie\n",
        "if not os.path.isfile(input_tif_file_path_FOV):                     # verify that the file exist\n",
        "    logging.error('Calcium video file not found.')\n",
        "\n",
        "input_tif_file_path = data_dir + 'raw/' + 'caiman_video_trial_0.tif'   # define the path of the raw ROI movie\n",
        "if not os.path.isfile(input_tif_file_path):                            # verify that the file exist\n",
        "    logging.error('Calcium video cropped file not found.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAltN-3Z_jbL"
      },
      "source": [
        "# videos visualization\n",
        "FOV = cm.load(input_tif_file_path_FOV)           # load complete FOV\n",
        "\n",
        "gain = 1.         #light intensity of video\n",
        "magnification = 1 #size of display movie\n",
        "fr = 20           #frequency of visualization (it is not sampling rate from the original movie)\n",
        "\n",
        "FOV.play(gain = gain, magnification = magnification, fr = fr) #show video of calcium fluorecence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uejRznze_jbO"
      },
      "source": [
        "# image visualization\n",
        "cropped_region_fig_path = figures_dir + 'FOV_calcium_video_1.png'       #path where the image will be saved\n",
        "\n",
        "auxiliary_functions.plot_FOV(FOV_file = input_tif_file_path_FOV , ROI_file = input_tif_file_path, \n",
        "                             output_file = cropped_region_fig_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ECz8FIG_jbP"
      },
      "source": [
        "For any process that tries to separate neurons from background it is important to take into account that the statistics of regions with neurons will be remarkably different from the statistics of regions with no neurons. With  1-photon imaging this is diffuse because background also includes activity from neurons in other focal planes (as explained above). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgF6NlEc_jbP"
      },
      "source": [
        "### Exercise 0. Image characteristics\n",
        "\n",
        "> Fluctuations in the activitation of the neuron can be directly observed on the video or in a temporal trace plot. Plotting the temporal trace will allow us to see the calcium transient dinamic, if a pixel belonging to a neuron is selected. Select a set of *N* random pixels from the ROI and plot the temporal evolution of pixel value. If the random pixels are choosen from an active neuron, you will be able to see the calcium transcient dynamic. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0FHwE04_jbU"
      },
      "source": [
        "***Answer:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQAExAQW_jbQ"
      },
      "source": [
        "temporal_pixel_evolution_fig_path = figures_dir + 'temporal_evolution_calcium_video_1.png'\n",
        "\n",
        "auxiliary_functions.temporal_evolution(file_name=input_tif_file_path, output_file_name=temporal_pixel_evolution_fig_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpmmTcp4eRog"
      },
      "source": [
        "## 1 Videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikhj-FdN_jbV"
      },
      "source": [
        "### Exercise 1. Video statistics\n",
        "\n",
        "> Compute the mean and correlation summary images for *caiman_video_trial_0.tif*. You can use *mean* and *corrcoef* functions from *numpy* for that aim. Note: Correlation image can be computed taking *m* nearby pixels. At this instance use 4 nearest-neighbords for each pixel. When using CaImAn we will use 8 nearest-neightbords. Plot the resulting summary images and the difference between them (make sure they are defined in the same range of relative values), and plot all in the same range [0,1].\n",
        "\n",
        "***Answer:***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHVlyQkr_jbW"
      },
      "source": [
        "''' Construct functions '''\n",
        "\n",
        "def summary_image_mean(video):\n",
        "    mean_im = np.mean(video, axis=0)\n",
        "    return mean_im\n",
        "    \n",
        "def summary_image_correlation(video):\n",
        "    video = video.T\n",
        "    cs = np.zeros((video.shape[0:2]))\n",
        "    for i in range(1, video.shape[0]-1):\n",
        "        for j in range(1, video.shape[1]-1):\n",
        "            file = video[i-1:i+2, j-1:j+2, :]\n",
        "            file = file.reshape(9, video.shape[2])\n",
        "            temp = np.corrcoef(file)\n",
        "            cs[i,j] = np.mean(temp[1:,0])\n",
        "    return cs.T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmTZ3ZeMeRol"
      },
      "source": [
        "''' Compute mean and correlation of summary images '''\n",
        "original_movie = cm.load(input_tif_file_path)\n",
        "mean_frame = summary_image_mean(original_movie)\n",
        "correlation_image = summary_image_correlation(original_movie)\n",
        "\n",
        "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
        "axs[0].set_title('Mean image')\n",
        "axs[0].imshow(mean_image, cmap='gray')\n",
        "axs[1].set_title('Correlation image')\n",
        "axs[1].imshow(corr_image, cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a85tQM4_jbZ"
      },
      "source": [
        "## plotting code is provided for once the mean and correlation summary images are computed\n",
        "figure, axes = plt.subplots(1,3)\n",
        "\n",
        "axes[0].set_xlabel('x', fontsize = 12)\n",
        "axes[0].set_ylabel('y', fontsize = 12)\n",
        "axes[0].set_title('Mean Summary Image', fontsize = 15)\n",
        "\n",
        "axes[1].set_xlabel('x', fontsize = 12)\n",
        "axes[1].set_ylabel('y', fontsize = 12)\n",
        "axes[1].set_title('Correlation Summary Image', fontsize = 15)\n",
        "\n",
        "axes[1].set_xlabel('x', fontsize = 12)\n",
        "axes[1].set_ylabel('y', fontsize = 12)\n",
        "axes[2].set_title('MSI - CSI', fontsize = 15)\n",
        "\n",
        "mesh0 = axes[0].pcolormesh(mean_frame/np.max(mean_frame), cmap = 'viridis')\n",
        "mesh1 = axes[1].pcolormesh(correlation_image, cmap = 'viridis')\n",
        "mesh2 = axes[2].pcolormesh(mean_frame/np.max(mean_frame)-correlation_image, cmap = 'viridis')\n",
        "\n",
        "vmin_corr = 0\n",
        "vmax_corr = 1\n",
        "mesh0.set_clim(vmin_corr,vmax_corr)\n",
        "mesh1.set_clim(vmin_corr,vmax_corr)\n",
        "mesh2.set_clim(vmin_corr,vmax_corr)\n",
        "\n",
        "\n",
        "figure.colorbar(mesh0,ax=axes[0])\n",
        "figure.colorbar(mesh1,ax=axes[1])\n",
        "figure.colorbar(mesh2,ax=axes[2])\n",
        "\n",
        "figure.set_size_inches(15,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLw-eIY8eRon"
      },
      "source": [
        "## 2 Preprocessing calcium videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFfn8Rjf_jbb"
      },
      "source": [
        "## parameters_motion_correction. We create them in a dictionary to prepare for caiman paramenters requirements\n",
        "\n",
        "parameters_motion_correction = { 'pw_rigid': True,  # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
        "                                'save_movie_rig': True, # flag to say whether the rigig motion corrected movie is saved\n",
        "                                'gSig_filt': (5, 5),     # size of high pass spatial filtering, used in 1p data\n",
        "                                'max_shifts': (25, 25),  # maximum allowed rigid shift in pixels (view the movie to get a sense of motion)\n",
        "                                'niter_rig': 1 ,\n",
        "                                'strides': (48, 48),     # create a new patch every x pixels for pw-rigid correction\n",
        "                                'overlaps': (96, 96),    # overlap between pathes (size of patch strides+overlaps)\n",
        "                                'upsample_factor_grid': 1,\n",
        "                                'num_frames_split': 80,  # length in frames of each chunk of the movie (to be processed in parallel)\n",
        "                                'max_deviation_rigid': 15, # maximum deviation allowed for patch with respect to rigid shifts\n",
        "                                'shifts_opencv': True, 'use_cuda': False, 'nonneg_movie': True,\n",
        "                                'border_nan': 'copy'}\n",
        "\n",
        "# load tif movie as a caiman movie object\n",
        "original_movie = cm.load(input_tif_file_path)\n",
        "# Calculate movie minimum to subtract from movie (this is necesary for running motion correction)\n",
        "min_mov = np.min(original_movie)\n",
        "# Apply the parameters to the CaImAn algorithm\n",
        "parameters_motion_correction['min_mov'] = min_mov\n",
        "opts = params.CNMFParams(params_dict = parameters_motion_correction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1swoe4l9_jbd"
      },
      "source": [
        "n_processes = psutil.cpu_count()\n",
        "cm.cluster.stop_server()\n",
        "# Start a new cluster\n",
        "c, dview, n_processes = cm.cluster.setup_cluster(backend='local', n_processes=n_processes, single_thread=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKvCs7h0_jbe"
      },
      "source": [
        "#create an object for motion correction\n",
        "mc = MotionCorrect(input_tif_file_path, dview = dview, **opts.get_group('motion'))\n",
        "# Perform rigid motion correction\n",
        "mc.motion_correct_rigid(save_movie = parameters_motion_correction['save_movie_rig'], template = None)\n",
        "m_rig = cm.load(mc.fname_tot_rig[0])\n",
        "fname_tot_rig = m_rig.save('calcium_video_1' +'_rig' + '.mmap',  order='C')\n",
        "# os.remove(os.path.join(mc.fname_tot_rig[0]))\n",
        "\n",
        "#perform non-rigid motion correction\n",
        "total_template_rig = mc.total_template_rig\n",
        "mc.motion_correct_pwrigid(save_movie=True, template = total_template_rig)\n",
        "fname_tot_els = mc.fname_tot_els[0]\n",
        "m_els = cm.load(fname_tot_els)\n",
        "fname_tot_els  = m_els.save('calcium_video_1' + '_els' + '.mmap',  order='C')\n",
        "# os.remove(mc.fname_tot_els[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3dfcStV_jbf"
      },
      "source": [
        "### Exercise 2. Rigid vs Non-Rigid motion correction\n",
        "\n",
        "> The objects *mc* contains information regarding the shifts produced by rigid and non-rigid motion corrections. For rigid motion correction you will find two vectors of size *500* frames corresponding to the shifts produced in each frame by rigid displacements. For non-rigid motion correction each atribute of the object contains multiple size *500* vectors corresponding to the shifts of all patches in *x* and *y* direction. \n",
        " * Plot the shifts produced by rigid and pw-rigid motion correction frame by frame. In the case of pw-rigid plot the mean and std from multiple patches in each direction.\n",
        " * Compare rigid and no-rigid shifts statistics. Plot histogram for both and compute relevants parametes. \n",
        " * Which mc algorithm would you expect to produce better outputs respect to the quality of the motion corrected image and why?\n",
        "\n",
        "Note: *use mc.shifts_rig, mc.x_shifts_els and mc.y_shifts_els*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqdMgzaMeRoq"
      },
      "source": [
        "***Answer:***\n",
        "\n",
        "- I would expect the pw-rigid motion correction to produce better outputs because it can shift various parts of the image over distinct distances. Thus, it is more flexible (has more degrees of freedom).\n",
        "- From the plots below, the difference in outputs between the methods is quite small. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghq2Y8Q4eRos"
      },
      "source": [
        "''' Get the motion correction shifts '''\n",
        "rig = np.array(mc.shifts_rig)\n",
        "els_x = np.array(mc.x_shifts_els)\n",
        "els_y = np.array(mc.y_shifts_els)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02ZoVsp9eRot"
      },
      "source": [
        "''' Use interactive plot to visualize the histograms '''\n",
        "def vis_hists(i, num_bins = 20):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
        "    \n",
        "    axs[0].set_title('Shifts in the x-direction')\n",
        "    axs[0].hist(els_x[i,:],bins=num_bins)\n",
        "    axs[0].axvline(rig[i,0], label='Rigid correction')\n",
        "    axs[0].axvline(np.mean(els_x[i,:]), label='Mean pw-rigid correction')\n",
        "    axs[0].legend()\n",
        "    \n",
        "    axs[1].set_title('Shifts in the y-direction')\n",
        "    axs[1].hist(els_y[i,:],bins=num_bins)\n",
        "    axs[1].axvline(rig[i,1], label='Rigid correction')\n",
        "    axs[1].axvline(np.mean(els_y[i,:]), label='Mean pw-rigid correction')\n",
        "    axs[1].legend()\n",
        "    \n",
        "    fig.suptitle(f'Frame number {i}')\n",
        "    plt.show()\n",
        "interact(vis_hists, i=widgets.IntSlider(min=0, max=(rig.shape[0]), value=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8INvLinJ_jbl"
      },
      "source": [
        "### Exercise 3. Quality assesment\n",
        "\n",
        "> Quality assesment by crispness is computed in a summary image that could be any of the ones previously mentioned.  \n",
        "* Compute the mean and correlation image for the original movie, the rigid motion corrected and the pw-motion corrected. You can use your previously done function or use the method local correlations from caiman object. You can see documantion and caiman demostration for this. \n",
        "* Plot the different summary images for original movie, rigid-motion corrected movie and pw-rigid motion corrected movie.\n",
        "* Create a function that computes the crispness as define above and use it to compute quality measure in the mean and correlation summary images. For that, just remove the border in the computations. Compare the crispness result after motion correction with the original value for the correlation image.\n",
        "* Defined as above, can cripsness be used directly to compare the motion quality of differnt videos with different image resolutions? what should be taken into account in order to compare them?\n",
        "\n",
        "***Answer:***\n",
        "\n",
        "On first inspection, the images are not that different, though the motion corrected images do seem more blurry. When we compute the crispness it is clear that the motion corrected images have lower crispness values, indicating a reduction in quality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg4dQoSl_jbm"
      },
      "source": [
        "''' Compute summary images '''\n",
        "original_movie_mean = summary_image_mean(original_movie)\n",
        "m_rig_mean = summary_image_mean(m_rig)\n",
        "m_els_mean = summary_image_mean(m_els)\n",
        "\n",
        "''' Complete code correlation summary image using caiman with 8 neighbours'''\n",
        "original_movie_corr = summary_image_corr(original_movie)\n",
        "m_rig_corr = summary_image_corr(m_rig)\n",
        "m_els_corr = summary_image_corr(m_els)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZa-znrneRou"
      },
      "source": [
        "Quality is measured by crispness, this is implemented in the  Caiman software."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VikYnzGIeRou"
      },
      "source": [
        "''' Compute crispness '''\n",
        "bord_px_rig = np.ceil(np.max(mc.shifts_rig)).astype(np.int)\n",
        "bord_px_els = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
        "final_size = np.subtract(mc.total_template_els.shape, 2 * bord_px_els) \n",
        "\n",
        "tmpl_rig, correlations_orig, flows_orig, norms_orig, crispness_orig = cm.motion_correction.compute_metrics_motion_correction(input_tif_file_path, final_size[0], final_size[1], swap_dim=False, winsize=100, play_flow=False)\n",
        "tmpl_rig, correlations_rig, flows_rig, norms_rig, crispness_rig = cm.motion_correction.compute_metrics_motion_correction(fname_tot_rig, final_size[0], final_size[1], swap_dim=False, winsize=100, play_flow=False)\n",
        "tmpl_els, correlations_els, flows_els, norms_els, crispness_els = cm.motion_correction.compute_metrics_motion_correction(fname_tot_els, final_size[0], final_size[1], swap_dim=False, winsize=100, play_flow=False)\n",
        "\n",
        "print(f'Original crispness {crispness_orig}')\n",
        "print(f'Rigid crispness {crispness_rig}')\n",
        "print(f'Elastic crispness {crispness_elastic}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cjp1nCqs_jbo"
      },
      "source": [
        "figure, axes = plt.subplots(2,3)\n",
        "figure.set_size_inches(15,7)\n",
        "\n",
        "mesh0 = axes[0,0].pcolormesh(original_movie_mean/np.max(original_movie_mean))\n",
        "axes[0,0].set_title('Original movie mean')\n",
        "mesh1 = axes[0,1].pcolormesh(m_rig_mean/np.max(m_rig_mean))\n",
        "axes[0,1].set_title('Rigig MC mean')\n",
        "mesh2 = axes[0,2].pcolormesh(m_els_mean/np.max(m_els_mean))\n",
        "axes[0,2].set_title('PW-rigid MC mean')\n",
        "\n",
        "mesh3 = axes[1,0].pcolormesh(original_movie_corr)\n",
        "axes[1,0].set_title('Original movie correlation')\n",
        "mesh4 = axes[1,1].pcolormesh(m_rig_corr)\n",
        "axes[1,1].set_title('Rigid MC correlation')\n",
        "mesh5= axes[1,2].pcolormesh(m_els_corr)\n",
        "axes[1,2].set_title('PW-Rigid MC correlation')\n",
        "\n",
        "vmin_corr = 0\n",
        "vmax_corr = 1\n",
        "mesh0.set_clim(vmin_corr,vmax_corr)\n",
        "mesh1.set_clim(vmin_corr,vmax_corr)\n",
        "mesh2.set_clim(vmin_corr,vmax_corr)\n",
        "mesh3.set_clim(vmin_corr,vmax_corr)\n",
        "mesh4.set_clim(vmin_corr,vmax_corr)\n",
        "mesh5.set_clim(vmin_corr,vmax_corr)\n",
        "\n",
        "figure.colorbar(mesh0,ax=axes[0,0])\n",
        "figure.colorbar(mesh1,ax=axes[0,1])\n",
        "figure.colorbar(mesh2,ax=axes[0,2])\n",
        "figure.colorbar(mesh3,ax=axes[1,0])\n",
        "figure.colorbar(mesh4,ax=axes[1,1])\n",
        "figure.colorbar(mesh5,ax=axes[1,2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueMWQPlz_jbv"
      },
      "source": [
        "#### Example of source extraction\n",
        "\n",
        "Here we will run an example on the video we have been working on for source extraction. First we will define some fixed parameters for this example and later we will explore the impact of those in the source extraction output (particularly the seeds for inicialization in CNMF-E). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxYQmvYH_jb2"
      },
      "source": [
        "# run source extraction (fit the model to the data)\n",
        "cnmf_object = cnmf.CNMF(n_processes=n_processes, dview=dview, params=opts)\n",
        "cnmf_object.fit(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oy-rJZq_jb6"
      },
      "source": [
        "# Save the cnmf object as a hdf5 file\n",
        "output_cnmf_file_path = data_dir + 'source_extracted/' + 'calcium_video_0_cnmf.hdf5'\n",
        "cnmf_object.save(output_cnmf_file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKWlG0gU_jb6"
      },
      "source": [
        "The main outputs from CNMF are the matrix **A** containing the footprints and the matrix **C** containing the temporal calcium traces. Here we show the result of the A matrix by ploting the footprints on top on the correlation image and also ploting the temporal traces. \n",
        "\n",
        "*Note: Footprints are save in cnmf_object.estimates.A and temporal traces in cnmf_object.estimates.C *"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmWoQvSf_jb8"
      },
      "source": [
        "# display footprints in the ROI\n",
        "figure, axes = plt.subplots(1)\n",
        "pos = axes.imshow(corr_image)\n",
        "coordinates = cm.utils.visualization.get_contours(cnmf_object.estimates.A, np.shape(corr_image), 0.2, 'max')\n",
        "for c in coordinates:\n",
        "    v = c['coordinates']\n",
        "    c['bbox'] = [np.floor(np.nanmin(v[:, 1])), np.ceil(np.nanmax(v[:, 1])),\n",
        "                    np.floor(np.nanmin(v[:, 0])), np.ceil(np.nanmax(v[:, 0]))]\n",
        "    axes.plot(*v.T, c='r')\n",
        "figure.colorbar(pos, ax=axes)\n",
        "\n",
        "print('Total number of componentes = ' + f'{cnmf_object.estimates.A.shape[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEB15raQ_jb8"
      },
      "source": [
        "# plot temporal traces\n",
        "figure, axes = plt.subplots(1)\n",
        "C_0 = cnmf_object.estimates.C.copy()\n",
        "C_0[1] += C_0[0].min()\n",
        "for i in range(1, len(C_0)):\n",
        "    C_0[i] += C_0[i].min() + C_0[:i].max()\n",
        "    axes.plot(C_0[i])\n",
        "axes.set_xlabel('t [frames]')\n",
        "axes.set_yticks([])\n",
        "axes.set_ylabel('activity')\n",
        "figure.set_size_inches([50., .5 * len(C_0)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2PWvih6_jcA"
      },
      "source": [
        "### Exercise 5. Source extraction parameters impact\n",
        "\n",
        "> * For a fixed minimum correlation value (ie 0.6) select a range of possible PNR minimun values and study the impact of those in the final source extraction output.\n",
        "  * For a fixed value of PNR (ie 6) select a range of minimum correlation value and study the impact of those in the final source extraction output.\n",
        "\n",
        "\n",
        "> * How do these parameters affect the spatial sparcity of the output? Which set of parameter selection procedes the higher number of neurons? Is maximal number of neurons always better? Why?  \n",
        "\n",
        "Smaller values for both the minimal value of the peak correlation images and peak noise ratio result in the detection of more neurons. If the value is too low the activity overlaps, which is a bad sign and may indicate noise. A maximal number of neurons is not always better because they may be false positives. We should therefore carefully select the values.\n",
        "\n",
        "> * Generate a plot of number of neurons vs PNR (or min corr value) to show how these parameters affect the source extracted signals.\n",
        "\n",
        "\n",
        "> * Are the temporal traces affected by these parameters?\n",
        "\n",
        "Yes.\n",
        "\n",
        "\n",
        "***Answer:***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K75EMlHveRoz"
      },
      "source": [
        "We first iterate over the correlation values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFhOTJbBeRo0"
      },
      "source": [
        "corr_values = np.linspace(0, 1, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knl-mknb_jcB"
      },
      "source": [
        "parameters_source_extraction ={ 'fr': 10,               # movie frame rate\n",
        "                               'decay_time': 0.1,       # length of a typical transient in seconds\n",
        "                               'min_corr': 0.7,         # min peak value from correlation image\n",
        "                               'min_pnr': 7,            # min peak to noise ration from PNR image\n",
        "                                'p': 1,                 # order of the autoregressive system \n",
        "                               'K': None,               # upper bound on number of components per patch, in general None\n",
        "                               'gSig': (4, 4),          # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
        "                               'gSiz': (17, 17),        # average diameter of a neuron, in general 4*gSig+1\n",
        "                               'ring_size_factor': 1.4, # radius of ring is gSiz*ring_size_factor\n",
        "                               'merge_thr': 0.7, 'rf': 60,\n",
        "                               'stride': 30, 'tsub': 1, 'ssub': 2, 'p_tsub': 1, 'p_ssub': 2, 'low_rank_background': None,\n",
        "                               'nb': 0, 'nb_patch': 0, 'ssub_B': 2, 'init_iter': 2,\n",
        "                               'method_init': 'corr_pnr', 'method_deconvolution': 'oasis',\n",
        "                               'update_background_components': True,\n",
        "                               'center_psf': True, 'border_pix': 0, 'normalize_init': False,\n",
        "                               'del_duplicates': True, 'only_init': True}\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 15))\n",
        "\n",
        "for ax, min_corr in zip(axes.flatten(), corr_values):\n",
        "    parameters_source_extraction['min_corr'] = min_corr\n",
        "    opts = params.CNMFParams(params_dict=parameters_source_extraction)\n",
        "    cnmf_object = cnmf.CNMF(n_processes=n_processes, dview=dview, params=opts)\n",
        "    cnmf_object.fit(images)\n",
        "    pos = ax.imshow(corr_image)\n",
        "    coordinates = cm.utils.visualization.get_contours(cnmf_object.estimates.A, np.shape(corr_image), 0.2, 'max')\n",
        "    for co in coordinates:\n",
        "        v = co['coordinates']\n",
        "        co['bbox'] = [np.floor(np.nanmin(v[:, 1])), np.ceil(np.nanmax(v[:, 1])), np.floor(np.nanmin(v[:, 0])), np.ceil(np.nanmax(v[:, 0]))]\n",
        "        ax.plot(*v.T, c='r')\n",
        "    ax.set_title(f'Min correlation footprints {min_corr} | number of cells {cnmf_object.estimates.A.shape[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ahxA4tteRo0"
      },
      "source": [
        "Then iterate over the PNR values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7gtVhVDeRo1"
      },
      "source": [
        "corr_values = np.linspace(0, 20, 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_MxEGqTeRo1"
      },
      "source": [
        "parameters_source_extraction ={ 'fr': 10,               # movie frame rate\n",
        "                               'decay_time': 0.1,       # length of a typical transient in seconds\n",
        "                               'min_corr': 0.7,         # min peak value from correlation image\n",
        "                               'min_pnr': 7,            # min peak to noise ration from PNR image\n",
        "                                'p': 1,                 # order of the autoregressive system \n",
        "                               'K': None,               # upper bound on number of components per patch, in general None\n",
        "                               'gSig': (4, 4),          # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
        "                               'gSiz': (17, 17),        # average diameter of a neuron, in general 4*gSig+1\n",
        "                               'ring_size_factor': 1.4, # radius of ring is gSiz*ring_size_factor\n",
        "                               'merge_thr': 0.7, 'rf': 60,\n",
        "                               'stride': 30, 'tsub': 1, 'ssub': 2, 'p_tsub': 1, 'p_ssub': 2, 'low_rank_background': None,\n",
        "                               'nb': 0, 'nb_patch': 0, 'ssub_B': 2, 'init_iter': 2,\n",
        "                               'method_init': 'corr_pnr', 'method_deconvolution': 'oasis',\n",
        "                               'update_background_components': True,\n",
        "                               'center_psf': True, 'border_pix': 0, 'normalize_init': False,\n",
        "                               'del_duplicates': True, 'only_init': True}\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(20, 15))\n",
        "\n",
        "for ax, min_pnr in tqdm(zip(axes.flatten(),corr_values)):\n",
        "    parameters_source_extraction['min_pnr'] = min_pnr\n",
        "    opts = params.CNMFParams(params_dict=parameters_source_extraction)\n",
        "    cnmf_object = cnmf.CNMF(n_processes=n_processes, dview=dview, params=opts)\n",
        "    cnmf_object.fit(images)\n",
        "    pos = ax.imshow(corr_image)\n",
        "    coordinates = cm.utils.visualization.get_contours(cnmf_object.estimates.A, np.shape(corr_image), 0.2, 'max')\n",
        "    for co in coordinates:\n",
        "        v = co['coordinates']\n",
        "        co['bbox'] = [np.floor(np.nanmin(v[:, 1])), np.ceil(np.nanmax(v[:, 1])), np.floor(np.nanmin(v[:, 0])), np.ceil(np.nanmax(v[:, 0]))]\n",
        "        ax.plot(*v.T, c='r')\n",
        "    ax.set_title(f'Min pnr footprints {min_pnr} | number of cells {cnmf_object.estimates.A.shape[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA-XJcz6_jcC"
      },
      "source": [
        "### Exercise 6. Photobleaching effect\n",
        "\n",
        "> * Study the effect of photobleaching in the raw signal. For that aim use the videos called *'caiman_video_trial_'+ f'{trial}' +'.tif'* to create a new multisession video.\n",
        ">* Repeat exercise 0 in this new signal. How is bleaching reflected in the temporal evolution of a set of random pixels for these signals? \n",
        "\n",
        "\n",
        "***Answer:***\n",
        "\n",
        "- In the figure below we can see that there is indeed an effect of the prolonged light exposure on the darkness of the images. The pixel values become darker as time progresses, shown in the temporal evolution and also in the histograms (skewed distributions to the left).\n",
        "- The peaks in the temporal evolutions likely indicate the start of a new trial.\n",
        "- So, photobleaching does affects the calcium imaging temporal traces, which introduces a challenge in analyzing the data. The bleaching is reflected in the downwards trend in the pixel valaues. This should be taken into account. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1hleRc1_jcC"
      },
      "source": [
        "# create a movie concatenating all segments on multiple trials\n",
        "output_tif_file_concatenated = data_dir + 'raw/' + 'movie_concatenated.tif'\n",
        "movie_list = [data_dir + 'raw/' + 'caiman_video_trial_' + str(i) + '.tif' for i in range(4+1)]\n",
        "\n",
        "# complete with concatenation\n",
        "concatenated_movie = load_movie_chain(movie_list)\n",
        "concatenated_file_path = data_dir + 'raw/' + 'concatenated_video.tif'\n",
        "concatenated_movie.save(concatenated_file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS-eAw8B_jcC"
      },
      "source": [
        "# temporal evolution visualization and statistics of pixels\n",
        "temporal_pixel_evo_fig_path = figures_dir + 'temporal_evolution_calcium_video_concatenated.png'\n",
        "\n",
        "auxiliary_functions.temporal_evolution(file_name=concatenated_file_path, output_file_name=temporal_pixel_evo_fig_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}